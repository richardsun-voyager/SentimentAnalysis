{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/intermediate_data/train_processed.csv')\n",
    "test_data = pd.read_csv('data/intermediate_data/test_processed.csv')\n",
    "train_processed = list(train_data.text.values)\n",
    "train_labels = list(train_data.sentiment.values)\n",
    "test_processed = list(test_data.text.values)\n",
    "test_labels = list(test_data.sentiment.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/glove.6B.100d.txt'\n",
    "word_emb = {}\n",
    "with open(file) as fi:\n",
    "    for line in fi:\n",
    "        items = line.split()\n",
    "        word_emb[items[0]] = np.array(items[1:], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocabulary size\n",
    "len(word_emb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word, vocab_embed):\n",
    "    try:\n",
    "        vec = vocab_embed[word]\n",
    "    except:\n",
    "        vec = word_emb['unk']\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent each sentence as the average embeddings of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computer the sent vector based on word vectors\n",
    "emb_size = 100\n",
    "train_sent_vecs = []\n",
    "for sent in train_processed:\n",
    "    words = sent.split()\n",
    "    sent_vec = np.zeros(emb_size)*1.0\n",
    "    for word in words:\n",
    "        vec = word2vec(word, word_emb)\n",
    "        sent_vec += vec\n",
    "    train_sent_vecs.append(sent_vec/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_vecs = []\n",
    "for sent in test_processed:\n",
    "    words = sent.split()\n",
    "    sent_vec = np.zeros(emb_size)*1.0\n",
    "    for word in words:\n",
    "        vec = word2vec(word, word_emb)\n",
    "        sent_vec += vec\n",
    "    test_sent_vecs.append(sent_vec/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "model = LogisticRegression()\n",
    "model.fit(train_sent_vecs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80124"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_sent_vecs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_sent_vecs, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_emb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(words)\n",
    "words = ['good', 'bad', 'nice', 'awesome', 'fuck', 'shit', 'positive']\n",
    "embs = []\n",
    "for w in words:\n",
    "    embs.append(word_emb[w])\n",
    "embs = np.stack(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "num_points = 400\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "two_d_embeddings = tsne.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAANSCAYAAAAge/zXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkjrzX237WhFN0eltAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(embeddings, labels):\n",
    "  assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "  plt.figure(figsize=(15,15))  # in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = embeddings[i,:]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                   ha='right', va='bottom')\n",
    "\n",
    "#words = [list(ti.get_vocab())[i] for i in range(1, num_points+1)]\n",
    "plot(two_d_embeddings, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lengths = [len(sent.split()) for sent in train_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10., 129., 177., 288., 464.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(sent_lengths, [0, 25, 50, 75, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computer the sent vector based on word vectors\n",
    "max_word_len = 800\n",
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_samples:\n",
    "    '''\n",
    "    Generate samples for training data or testing data\n",
    "    '''\n",
    "    def __init__(self, data, labels, is_training=True):\n",
    "        '''\n",
    "        Args:\n",
    "        data: numpy\n",
    "        labels: numpy\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.is_training = is_training\n",
    "        self.index = 0\n",
    "        \n",
    "    def generate_samples(self, sents, labels, batch_size=64):\n",
    "        '''\n",
    "        Select a batch_size of sentences\n",
    "        Transform each sentence into a sequence of embeddings\n",
    "        '''\n",
    "        indice = np.random.choice(len(sents), batch_size)\n",
    "        sents = sents[indice]\n",
    "        labels = labels[indice]\n",
    "        sent_vecs, sent_lens = self.create_sent_emb(sents)\n",
    "        return sent_vecs, labels, sent_lens\n",
    "    \n",
    "    def create_sent_emb(self, sents):\n",
    "        '''\n",
    "        Create sequences of word embeddings for sentences\n",
    "        '''\n",
    "        sent_vecs = []#A matrix represents a sentence\n",
    "        sent_lens = []#length of each sentence\n",
    "        for sent in sents:\n",
    "            words = sent.split()\n",
    "            sent_lens.append(len(words))\n",
    "            sent_vec = []\n",
    "            for word in words:\n",
    "                vec = word2vec(word, word_emb)\n",
    "                sent_vec.append(vec)\n",
    "            #Cut long sentence\n",
    "            if len(words) > max_word_len:\n",
    "                sent_vec = sent_vec[:max_word_len]\n",
    "            #Pad short sentence\n",
    "            if len(words) < max_word_len:\n",
    "                for _ in np.arange(max_word_len - len(words)):\n",
    "                    vec = np.zeros(emb_size)\n",
    "                    sent_vec.append(vec)\n",
    "            sent_vec = np.stack(sent_vec)\n",
    "            sent_vecs.append(sent_vec)\n",
    "        sent_vecs = np.stack(sent_vecs)\n",
    "        return sent_vecs, sent_lens\n",
    "        \n",
    "    def generate(self, batch_size=64):\n",
    "        if self.is_training:\n",
    "            sent_vecs, sent_labels, lengths = self.generate_samples(self.data, \n",
    "                                                               self.labels,\n",
    "                                                              batch_size)\n",
    "        else:\n",
    "            start = self.index\n",
    "            end = start + batch_size\n",
    "            if end > len(self.data):\n",
    "                print('Out of sample size')\n",
    "                self.index = 0\n",
    "            sents = self.data[start:end]\n",
    "            sent_labels = self.labels[start:end]\n",
    "            sent_vecs, lengths = self.create_sent_emb(sents)\n",
    "            self.index = end\n",
    "        return sent_vecs, sent_labels, lengths\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gs = generate_samples(np.array(train_processed), np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs, sent_labels, lengths = train_gs.generate(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gs = generate_samples(np.array(test_processed), np.array(test_labels), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs, sent_labels, lengths = test_gs.generate(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from models.CNN_Pretrained_Embedding import CNN_Model_Pretrained_Emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250\n",
    "    batch_size = 64\n",
    "    layer_size = 2\n",
    "    \n",
    "class testConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250\n",
    "    batch_size = 64\n",
    "    layer_size = 2\n",
    "    \n",
    "class singleConfig:\n",
    "    max_doc_len = max_word_len\n",
    "    label_size = 2\n",
    "    embed_size = 100\n",
    "    hidden_size = 250#hidden size for hidden state of rnn\n",
    "    batch_size = 1\n",
    "    layer_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized!\n",
      "Model Initialized!\n",
      "Model Initialized!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "graph_cnn = tf.Graph()\n",
    "#Create models for training and testing data\n",
    "with graph_cnn.as_default():\n",
    "    initializer = tf.random_uniform_initializer(-0.02, 0.02)\n",
    "    with tf.name_scope('train'):\n",
    "        #Set different models for different buckets\n",
    "        with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "            train_model = CNN_Model_Pretrained_Emb(trainConfig)\n",
    "            saver=tf.train.Saver()\n",
    "    with tf.name_scope('test'):\n",
    "        #Set different models for different buckets\n",
    "        with tf.variable_scope(\"Model\", reuse=True, initializer=initializer):\n",
    "            test_model = CNN_Model_Pretrained_Emb(testConfig, False)\n",
    "            single_model = CNN_Model_Pretrained_Emb(singleConfig, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chunk_num = int(len(train_processed)/trainConfig.batch_size)\n",
    "test_chunk_num = int(len(test_processed)/testConfig.batch_size)\n",
    "train_chunk_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_num = len(test_processed) - test_chunk_num * testConfig.batch_size\n",
    "remain_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt_cnn_pretrained_emb/cnn.ckpt\n",
      "Loss: 0.5197\n",
      "Loss: 0.5306\n"
     ]
    }
   ],
   "source": [
    "import time, os\n",
    "epochs = 2\n",
    "#train_chunk_num = 10\n",
    "file = \"ckpt_cnn_pretrained_emb/cnn.ckpt\"\n",
    "with tf.Session(graph=graph_cnn) as sess:\n",
    "    #Initialize parameters\n",
    "    init = tf.global_variables_initializer()\n",
    "    if not os.path.exists(\"ckpt_cnn_pretrained_emb\"):\n",
    "        os.mkdir('ckpt_cnn_pretrained_emb')\n",
    "    if os.path.exists(\"ckpt_cnn_pretrained_emb/cnn.ckpt.index\"):\n",
    "        saver.restore(sess, file)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    start_time = time.time()\n",
    "    for m in range(epochs):\n",
    "        for i in range(train_chunk_num):\n",
    "            #sess.run(tf.assign(learning_rate, 0.002*((0.98)**m)))\n",
    "            x, y, lengths = train_gs.generate(trainConfig.batch_size)\n",
    "            feed_dict = {train_model.x:x, train_model.y:y, train_model.lengths:lengths}\n",
    "            l, _ = sess.run([train_model.cost, train_model.optimize], feed_dict=feed_dict)\n",
    "            if i%100 == 0:\n",
    "                print('Loss:', round(l, 4))\n",
    "        end_time = time.time()\n",
    "        print('Epoch', m, 'time:{:.2f}'.format(end_time - start_time))\n",
    "        \n",
    "    saver.save(sess,'ckpt_cnn_pretrained_emb/cnn.ckpt')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Testing Accuracy\n",
    "with tf.Session(graph=graph_cnn) as sess:\n",
    "    print('Testing...')\n",
    "    count = 0\n",
    "    #saver = tf.train.import_meta_graph('ckpt_cnn/cnn.ckpt.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('ckpt_cnn_pretrained_emb/'))\n",
    "    print('Parameters restored')\n",
    "    start_time = time.time()\n",
    "    test_gs = generate_samples(np.array(test_processed), np.array(test_labels), False)\n",
    "    for _ in range(test_chunk_num):\n",
    "        #Traverse each data\n",
    "        x, y, lengths = test_gs.generate(testConfig.batch_size)\n",
    "        feed_dict = {test_model.x:x, test_model.y:y, test_model.lengths:lengths}\n",
    "        n = sess.run(test_model.correct_num, feed_dict=feed_dict)\n",
    "        count += np.sum(n)\n",
    "    for _ in range(remain_num):\n",
    "        #Traverse each data\n",
    "        x, y, lengths = test_gs.generate(1)\n",
    "        feed_dict = {single_model.x:x, single_model.y:y, \n",
    "                     single_model.lengths:lengths}\n",
    "        n = sess.run(single_model.correct_num, feed_dict=feed_dict)\n",
    "        count += np.sum(n)\n",
    "    end_time = time.time()\n",
    "    print('Testing Time:{:.2f}'.format(end_time - start_time))\n",
    "    print(count*1.0/len(test_processed)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of CNN based on pretrained-Glove word embeddings i 0.83876."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
